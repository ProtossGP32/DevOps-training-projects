[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "devops-exercises/explore-california/00-introduction.html",
    "href": "devops-exercises/explore-california/00-introduction.html",
    "title": "Explore California - Static website debugging and deployment",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "homelab-project/00-introduction.html",
    "href": "homelab-project/00-introduction.html",
    "title": "Homelab project introduction",
    "section": "",
    "text": "First of all\nBig thank you to Lars Kiesow and his awesome guide on how to configure a home lab with Proxmox VE from the start and very well explained, no shortcuts at all.\n\nLink to the guide here\nYou can also check the original MD files in its GitHub repository here\nAlso check the proxmox branch for some new insights still not pushed to the main branch here\n\n\n\nRationale\n\n\n\n\n\n\nTODO\n\n\n\nPending. Add some architecture diagram to better understand what we’re trying to achieve."
  },
  {
    "objectID": "homelab-project/requirements/00-requirements.html",
    "href": "homelab-project/requirements/00-requirements.html",
    "title": "Homelab Requirements",
    "section": "",
    "text": "Any relatively modern desktop computes can be used as a homelab. In my case I’ll be using an HP Compaq Elite 8300 with an Intel Core i5 (4 cores), 24Gb or RAM and a single NIC."
  },
  {
    "objectID": "homelab-project/requirements/00-requirements.html#virtualization-suite",
    "href": "homelab-project/requirements/00-requirements.html#virtualization-suite",
    "title": "Homelab Requirements",
    "section": "Virtualization suite",
    "text": "Virtualization suite\nIn order to comply with the previous statement, we’ll be using Proxmox VE, a Virtualization suite that acts as a HyperVisor as well as a Linux Containers deployer."
  },
  {
    "objectID": "homelab-project/requirements/00-requirements.html#network-management",
    "href": "homelab-project/requirements/00-requirements.html#network-management",
    "title": "Homelab Requirements",
    "section": "Network management",
    "text": "Network management\nVirtual hosts should have their own internal network so they don’t interfere with other local DHCP servers or even access external networks at all."
  },
  {
    "objectID": "homelab-project/requirements/00-requirements.html#self-hosted-software",
    "href": "homelab-project/requirements/00-requirements.html#self-hosted-software",
    "title": "Homelab Requirements",
    "section": "Self-hosted software",
    "text": "Self-hosted software\nWe’d like to host our own services, and again the best approach should be to deploy containers, either as-is or in an orchestrated environment such as Kubernetes."
  },
  {
    "objectID": "homelab-project/virtualization-server/01-installing-proxmox.html",
    "href": "homelab-project/virtualization-server/01-installing-proxmox.html",
    "title": "Part 1 - Installing Proxmox VE",
    "section": "",
    "text": "TODO\n\n\n\nPending to describe Proxmox"
  },
  {
    "objectID": "homelab-project/virtualization-server/01-installing-proxmox.html#ip-address-assigned-via-dhcp",
    "href": "homelab-project/virtualization-server/01-installing-proxmox.html#ip-address-assigned-via-dhcp",
    "title": "Part 1 - Installing Proxmox VE",
    "section": "IP address assigned via DHCP",
    "text": "IP address assigned via DHCP\nThis way the DHCP server will assign the correct domain name and the server will be accessible by its domain name.\nA server should always have a predictable IP, so configure the DHCP server to lease the same IP to the Proxmox server network MAC address.\n\n\n\n\n\n\nTODO\n\n\n\nPending to elaborate\n\n\n\n\n\n\n\n\nRegarding DNS and DHCP servers…\n\n\n\nLater on, we’ll configure our own virtual DHCP and DNS servers to provide internal IPs to our VM and containers."
  },
  {
    "objectID": "homelab-project/virtualization-server/01-installing-proxmox.html#allow-https-on-port-443-via-nginx",
    "href": "homelab-project/virtualization-server/01-installing-proxmox.html#allow-https-on-port-443-via-nginx",
    "title": "Part 1 - Installing Proxmox VE",
    "section": "Allow HTTPS on Port 443 via Nginx",
    "text": "Allow HTTPS on Port 443 via Nginx\nAs Lars mentions in his guide, the web interface of Proxmox is available on port 8006 instead of the default HTTPS port 443, and HTTP on Port 80 is not available at all.\nHaving HTTPS acesses through ports different than 443 can be very bothersome as we need to remember what exact port is the one used on each service.\nIn order to solve this, we’ll use a light-weight web server that also acts as a reverse proxy natively in the Proxmox server, so we can redirect 443 requests to the 8006 port.\n\n\n\n\n\n\nAbout Nginx…\n\n\n\nLater on we’ll be also deploying other Nginx servers within our internal networks to redirect traffic to each one of our services\n\n\n\nInstall and Configure Nginx\nConnect via SSH to the PVE server as root:\nssh root@<proxmox-ip>\n# or\nssh root@<proxmox-hostname>.<local-domain>\nInstall the nginx-light package:\napt-get install nginx-light\nA web server should already be up and running. Verify it by accessing http://<proxmox-ip>/ or http://<proxmox-hostname>.<local-domain>, a blank welcome screen should appear.\n\n\n\nNginx welcome web page\n\n\nOnce done, remove the default Nginx configuration from the Proxmox server…\nrm /etc/nginx/sites-*/default\n…and create a new file /etc/nginx/sites-available/proxmox-web-interface with the following content:\n\n\n/etc/nginx/sites-available/proxmox-web-interface\n\nserver {\n  # Enforce HTTPS by redirecting requests\n  listen 80;\n  listen [::]:80;\n  server_name pve.protossnet.local;\n\n  location / {\n    return 301 https://pve.protossnet.local$request_uri;\n  }\n}\n\nserver {\n  listen 443 ssl http2;\n  listen [::]:443 ssl http2;\n  server_name pve.protossnet.local;\n\n  ssl_certificate_key /etc/pve/local/pve-ssl.key;\n  ssl_certificate     /etc/pve/local/pve-ssl.pem;\n\n  # Proxy configuration\n  location / {\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_pass https://127.0.0.1:8006;\n    proxy_buffering off;\n    client_max_body_size 0;\n    proxy_connect_timeout  3600s;\n    proxy_read_timeout  3600s;\n    proxy_send_timeout  3600s;\n    send_timeout  3600s;\n    proxy_set_header Host $host;\n    proxy_ssl_name $host;\n    proxy_set_header X-Forwarded-For $remote_addr;\n  }\n}\n\n\n\n\n\n\n\nNote\n\n\n\nLars has additional and more complex Nginx configs for the web interface, it’s worth checking them out to learn about how Nginx works and how powerful it can be!\n\n\nAfter updating the configuration, we must create a softlink from the sites-enabled directory to make it available:\ncd /etc/nginx/sites-enabled\nln -s /etc/nginx/sites-available/proxmox-web-interface\nFinally, we check if Nginx can spot any errors:\nnginx -t\n\n\nRestart Nginx and Enable it by Default\nTo start Nginx and make sure it starts automatically after a system reboot, run:\n# Restart the Nginx service\nsystemctl restart nginx.service\n# Permanently enable the Nginx service\nsystemctl enable nginx.service\nFinally, make sure that Nginx will start only after Proxmox starts, since the certificates may otherwise not be available yet. To do that, create a file /etc/systemd/system/nginx.service.d/override.conf with the content:\n[Unit]\nRequires=pve-cluster.service\nAfter=pve-cluster.service\nAlternatively, you can also use systemctl edit nginx.service to edit this file.\nWith the service restarted, check that we can access the Proxmox VE web interface through the expected HTTPS port by going to https://<proxmox-hostname>.<local-domain> or https://<proxmox-ip>:\n\n\n\nProxmox - Nginx correctly redirecting HTTPS request\n\n\n\n\n\n\n\n\nWhat about the insecure HTTPS warning?\n\n\n\nRight now Nginx is using the SSL certificates provided by Proxmox on installation time. We should provide valid SSL certifications to avoid this, such as the ones that Let’s Encript can generate.\n\n\n\n\nMake Proxmox UI Service Listen to Localhost Only\n\n\n\n\n\n\nLars suggests this change to ensure that everyone is using the Nginx set-up, but I don’t really understand what exactly means. I’ve applied the change and at least I can still access it from within my local network.\n\n\n\nCreate /etc/default/pveproxy and set:\nLISTEN_IP=\"127.0.0.1\"\nThen restart the pveproxy service:\nsystemctl restart pveproxy.service"
  },
  {
    "objectID": "homelab-project/virtualization-server/02-virtual-networks.html",
    "href": "homelab-project/virtualization-server/02-virtual-networks.html",
    "title": "Part 2 - Internal Virtual Networks",
    "section": "",
    "text": "Virtual networks are network interfaces that act as fake NICs and allow multiple VM or LXC to communicate within the same subnet. A virtual network can be bridged or bonded to a physical NIC or can live on its own without access to external devices (we’ll call them internal networks); the latter are useful when we have a cluster of resources that don’t need to reach external networks."
  },
  {
    "objectID": "homelab-project/virtualization-server/02-virtual-networks.html#build-a-proxmox-internal-network",
    "href": "homelab-project/virtualization-server/02-virtual-networks.html#build-a-proxmox-internal-network",
    "title": "Part 2 - Internal Virtual Networks",
    "section": "Build a Proxmox Internal Network",
    "text": "Build a Proxmox Internal Network\nFirst of all, we need to create a new network interface on our Proxmox server and assign it a network. This network bridge can then later be used to put machines on the internal network.\nThis gives us a fully functional internal network to use.\n\n\n\n\n\n\nMind the network transparency!\n\n\n\nAs Lars explains, the downside of having internal networks for clusters of VM is that we lose network transparency in that if a VM starts to behave erratically, its effect on the network level will be masked behind the Proxmox real IP, thus being unable to quickly identify the actual culprit.\nOn production environments, this would end in the IT department cutting down network access to the Proxmox server, and therefore to any VM machine inside it.\n\n\nAs a starting point, create a new network bridge in the Proxmox web interface:\n\nHead to Datacenter → Proxmox server name → Network, clic Create → Linux Bridge and set something like:\n\nName: vmbr1\nIPv4/CIDR: 10.0.0.1/16\nAutostart: ✓\nComment: Internal network\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis example provides an internal /16 network, more than enough for our inter machine configuration (65.536 IP addresses, being 65.534 usable!):\n\nNetwork Address: 10.0.0.0\nUsable IP range: 10.0.0.1 ~ 10.0.255.254\nBroadcast Address: 10.0.255.255\n\nIn most cases, using a /24 should be enough (253 IP addresses).\n\n\nThe file /etc/network/interfaces keeps the network interfaces configuration of the server. Once created the new interface, you should see the following new configuration block:\n\n\n/etc/network/interfaces\n\nauto vmbr1\niface vmbr1 inet static\n   address 10.0.0.1/16\n   bridge-ports none\n   bridge-stp off\n   bridge-fd 0\n\nOnce done, bring the new network interface up using:\nifup vmbr1\nAnd check its status by running:\nip a\n...\n4: vmbr1: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default qlen 1000\n    link/ether 32:7b:7f:8b:f8:9c brd ff:ff:ff:ff:ff:ff\n    inet 10.0.0.1/16 scope global vmbr1\n       valid_lft forever preferred_lft forever\nWith this, we have a fully functional network interface for our internal VMs and containers, but without access to the outside world.\n\n\n\n\n\n\nWhat about the state DOWN?\n\n\n\nThat’s because there’s no host using it yet. What’s important is that the inet is correctly configured as 10.0.0.1/16.\nOnce we attach this interface to some containers or VM, its state will change to UP.\n\n\n\n\n\n\n\n\nCommenting on Networks\n\n\n\nLars has a point when mentioning the importance of giving proper comments to each network interface. While it might seem unnecessary when dealing with just a few interfaces, we can forget about it once the number of appliances and services grow.\nThus, the default vmbr0 created on Proxmox installation time and with proper access to the outside shall be named External network, while the new vmbr1 shall be called Internal network. This way we avoid any kind of doubt when picking one of them. Use similar criteria with any new network interface.\n\n\n\nNAT Configuration\nOur current network interface vmbr1 can be useful for appliances that don’t require to access the internet (i.e. servers that simply execute local tasks and talk to each other). If we want this network interface to be able to reach the outside world, we need a NAT configuration.\n\n\n\n\n\n\nNAT\n\n\n\nNAT is the process where all traffic from a network is routed through a single IP address outside that network, and then return results to the request source.\n\n\nIn order to configure NAT in our interface, edit the file /etc/network/interface and add the following lines to the vmbr1 config block:\n\n\n/etc/network/interface\n\niface vmbr1 inet static\n   ...\n   post-up   echo 1 > /proc/sys/net/ipv4/ip_forward\n   post-up   iptables -t nat -A POSTROUTING -s '10.0.0.0/16' -o vmbr0 -j MASQUERADE\n   post-down iptables -t nat -D POSTROUTING -s '10.0.0.0/16' -o vmbr0 -j MASQUERADE\n\nWhat we are doing here is add rules to the interface, telling it how to route the packages in that network. This rule will create a dynamic source NAT where every packet from 10.0.0.0/16 will be sent to the interface vmbr0 (the External network) and the source IP address of this packet will be replaced by the primary IP of vmbr0 (the Proxmox server IP).\n\nSetting 1 to /proc/sys/net/ipv4/ip_forward enables to forward packages to another interface (TODO: needs references)\nThe -t nat -A POSTROUTING rule means that it allows the vmbr0 interface to route packages from the source -s '10.0.0.0/16', only after the interface vmbr1 is UP, that’s why it is defined as a post-up rule\nThe -t nat -D POSTROUTING rule does the opposite, denies any routing of packages from source -s '10.0.0.0' once the vmbr1 interface is DOWN, ensuring that no unexpected packages are routed through vmbr0\n\n\n\nTesting your Configuration\nFirst, make sure that both interfaces are up, either by executing ifup <interface name> or by rebooting the whole server.\nNext setup a simple container or virtual machine, assign vmbr1 interface as its Network interface and statically configure its IP and gateway according to the interface range. For example:\n\nBridge: vmbr1\nIPv4/CIDR: 10.0.0.2/16\nGateway (IPv4): 10.0.0.1\n\nOnce started, ssh into that server/container and try pinging any external server IP. Remember that there’s no DNS server for this network, so we can’t use domain names yet:\n\n\nPing test:\n\n# Let's try pinging Google\nping -4 -c 1 8.8.8.8\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=119 time=18.8 ms\n\n--- 8.8.8.8 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 18.764/18.764/18.764/0.000 ms\n\nThe ping command has returned results, so the network has access to external servers!"
  },
  {
    "objectID": "homelab-project/virtualization-server/03-dns-dhcp-servers.html",
    "href": "homelab-project/virtualization-server/03-dns-dhcp-servers.html",
    "title": "Part 3 - DNS and DHCP servers",
    "section": "",
    "text": "Wait, more DHCP servers? Why?\n\n\n\nYou might be thinking about the DHCP server that provides the IP address to the Proxmox server and wondering why this server can’t handle the IP assignment of the future VMs. Here’s why:\nA DHCP server only serves IPs within a certain established range, and we might not have access to it (restricted MAC access, limited number of IPs, etc…). Furthermore, we’ve created an internal network interface whose IP range shouldn’t match with the upstream server and is also masquerading its IPs behind the Proxmox server one (remember NAT?). Having said that, the next course of action is to create custom DHCP and DNS servers for each internal network.\nLater on, we’ll discuss how to allow multiple internal networks to talk to each other, but for now we’ll only use one.\nWe’ll be using dnsmasq to host a DHCP and DNS server either on the Proxmox server itself or on a machine or container running in Proxmox. What approach is better? It always depends on your needs:\nIn order to touch the least the Proxmox internal configurations and avoid messing with other active DHCP servers, we’ll go with the Container route. If you want to go with the Proxmox Server set-up, Lars also explains it here."
  },
  {
    "objectID": "homelab-project/virtualization-server/03-dns-dhcp-servers.html#using-a-container",
    "href": "homelab-project/virtualization-server/03-dns-dhcp-servers.html#using-a-container",
    "title": "Part 3 - DNS and DHCP servers",
    "section": "Using a container",
    "text": "Using a container\n\n\n\n\n\n\nContainer creation guide\n\n\n\nLXC - Linux Containers on Proxmox\n\n\nCreate a Debian container with 128 MB of RAM and assign it a static IPv4 address on the internal network (vmbr1 or check the interface comments). Make sure the IPv4 address is unique and does not clash with already assigned addresses. As DNS and DHCP services are quite important in a network, it’s usual to assign them the first or the last usable IP within the range; as we’re using 10.0.0.1 as our gateway (the Proxmox server), the next available one is 10.0.0.2:\n\nBridge: vmbr1\nIPv4: Static\nIPv4/CIDR: 10.0.0.2/16\nGateway (IPv4): 10.0.0.1\n\n\n\n\n\n\n\nAlpine instead of Debian\n\n\n\nFor the sake of using even more minimal distributions, I’ve used Alpine as it is very lightweigh. When using it, just remember that its package manager is apk instead of apt, and that installing new packages is done with add instead of install.\n\n\nMake sure to update the container as usual:\n# Alpine\napk update\napk upgrade\n\n# Debian\napt update\napt upgrade\nDebian only! The Proxmox Debian container template comes with systemd-resolved enabled. This service conflicts with dnsmasq and we don’t actually need it, so we disable it:\nsystemctl stop systemd-resolved.service\nsystemctl disable systemd-resolved.service\nNow we install dnsmasq:\n# Alpine\napk add dnsmasq\n\n# Debian\napt install dnsmasq\nAs usual, Debian will automatically start the service after its installation (this doesn’t happen in Alpine). But by default dnsmasq is configured as a DNS server only, so we need to add additional configuration to enable the DHCP feature. In any case, create a file /etc/dnsmasq.d/internal.conf with the following configuration:\n\n\n/etc/dnsmasq.d/internal.conf\n\n# Tells dnsmasq to never forward A or AAAA queries for plain names,\n# without dots or domain parts, to upstream nameservers.\n# If the name is not known from /etc/hosts or DHCP then a \"not found\" answer is\n# returned.\ndomain-needed\n\n# All reverse lookups for private IP ranges (ie 192.168.x.x, etc) which are not\n# found in /etc/hosts or the DHCP leases file are answered with \"no such domain\"\n# rather than being forwarded upstream.\nbogus-priv\n\n# Don't read /etc/resolv.conf. Get upstream servers only from the command line\n# or the dnsmasq configuration file.\nno-resolv\n\n# Later  versions of windows make periodic DNS requests which don't get sensible\n# answers from the public DNS and can cause problems by triggering dial-on-\n# demand links. This flag turns on an option to filter such requests. The\n# requests blocked are for records of types SOA and SRV, and type  ANY  where\n# the requested name has underscores, to catch LDAP requests.\nfilterwin2k\n\n# Add the domain to simple names (without a period) in /etc/hosts in the same\n# way as for DHCP-derived names. Note that this does not apply to domain names\n# in cnames, PTR records, TXT records etc.\nexpand-hosts\n\n# Specifies DNS domains for the DHCP server. This  has  two  effects;\n# firstly it causes the DHCP server to return the domain to any hosts which\n# request it, and secondly it sets the domain which is legal for DHCP-configured\n# hosts to claim.  In addition, when a suffix is set then hostnames without a\n# domain part have the suffix added as an optional domain part.\n# Example: In Proxmox, you create a Debian container with the hostname `test`.\n# This host would be available as `test.pve-internal.home.lkiesow.io`.\ndomain=pve-internal.protossnet.local\n\n# This configures local-only domains.\n# Queries in these domains are answered from /etc/hosts or DHCP only.\n# Queries for these domains are never forwarded to upstream names servers.\nlocal=/pve-internal.protossnet.local/\n\n# Listen on the given IP address(es) only to limit to what interfaces dnsmasq\n# should respond to.\n# This should be the IP address of your dnsmasq in your internal network.\nlisten-address=127.0.0.1\nlisten-address=10.0.0.2\n\n# Upstream DNS servers\n# We told dnsmasq to ignore the resolv.conf and thus need to explicitely specify\n# the upstream name servers. Use Cloudflare's and Google's DNS server or specify\n# a custom one.\n#server=1.1.1.1\n#server=8.8.8.8\n# Using the pi.hole deployed within Proxmox\nserver=192.168.1.6\n\n# DHCP range\n# Enable the DHCP server. Addresses will be given out from this range.\n# The following reserves 10.0.0.1 to 10.0.0.255 for static addresses not handled\n# by DHCP like the address for our Proxmox or dnsmasq server.\ndhcp-range=10.0.1.0,10.0.255.255\n\n# Set the advertised default route to the IP address of our Proxmox server.\ndhcp-option=option:router,10.0.0.1\n\n\n\n\n\n\n\nCareful with the .conf extension!\n\n\n\nLars doesn’t define an extension for the dnsmasq config file, but in Alpine distros this is the only extension accepted, so non-extension files are discarded. Bear this in mind when troubleshooting the service.\n\n\n\n\n\n\n\n\nMind the DHCP range!\n\n\n\nThe dhcp-range parameter is set between 10.0.1.0 and 10.0.255.255, meaning that the range between 10.0.0.1 and 10.0.0.255 is excluded. This is intentionally done, as they should be static addresses assigned to critical servers such as the Proxmox server (10.0.0.1) or the dnsmasq server itself (10.0.0.2).\n\n\n\n\n\n\n\n\nIf pointing to an upstream DNS server, what’s the purpose of this one, then?\n\n\n\nIn the dnsmasq config we define the server as our Pi-Hole server (192.168.1.6). This has upstream DNS servers that will resolve any domain name outside the internal network.\ndnsmasq provides resolution for the FQDN and hostnames within the internal network.\n\n\nFinally, restart and enable dnsmasq and check that it is up and running:\n# Both Debian and Alpine - Service restart\nservice dnsmasq restart\n# Debian - Enable service at boot time\nservice dnsmasq enable\n# Alpine - Add service at boot time\nrc-update add dnsmasq\n# Both Debian and Alpine - Service status\nservice dnsmasq.service status\n\n# Output for each command\n# Restart (Alpine)\n * Caching service dependencies ... [ ok ]\n * /var/lib/misc/dnsmasq.leases: creating file\n * /var/lib/misc/dnsmasq.leases: correcting owner\n * Starting dnsmasq ... [ ok ]\n# Enable (Alpine)\n * service dnsmasq added to runlevel default\n# Status (Alpine)\n * status: started"
  },
  {
    "objectID": "homelab-project/virtualization-server/03-dns-dhcp-servers.html#test-the-set-up",
    "href": "homelab-project/virtualization-server/03-dns-dhcp-servers.html#test-the-set-up",
    "title": "Part 3 - DNS and DHCP servers",
    "section": "Test the Set-Up",
    "text": "Test the Set-Up\nCreate two containers test-a and test-b, put them on the internal network by selecting vmbr1 as network bridge and set the IPv4 network configuration to DHCP. The logs in the dnsmasq server should show how it has assigned an IP to both containers (DHCPACK are the lines that prove it):\n\n\n/var/log/messages\n\nJan 16 22:57:35 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCP, IP range 10.0.1.0 -- 10.0.255.255, lease time 1h\nJan 16 22:57:35 vmbr1-dnsmasq daemon.info dnsmasq[741]: using nameserver 192.168.1.6#53\nJan 16 22:57:35 vmbr1-dnsmasq daemon.info dnsmasq[741]: using only locally-known addresses for pve-internal.protossnet.local\nJan 16 22:57:35 vmbr1-dnsmasq daemon.info dnsmasq[741]: read /etc/hosts - 4 addresses\nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPDISCOVER(eth0) c6:d8:bc:22:dc:4a \nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPOFFER(eth0) 10.0.4.102 c6:d8:bc:22:dc:4a \nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPDISCOVER(eth0) c6:d8:bc:22:dc:4a \nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPOFFER(eth0) 10.0.4.102 c6:d8:bc:22:dc:4a \nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPREQUEST(eth0) 10.0.4.102 c6:d8:bc:22:dc:4a\n# DHCPACK for test-a: IP assigned is 10.0.4.102\nJan 16 22:57:42 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPACK(eth0) 10.0.4.102 c6:d8:bc:22:dc:4a test-a\nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPDISCOVER(eth0) 4e:70:ba:1e:73:ff \nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPOFFER(eth0) 10.0.61.210 4e:70:ba:1e:73:ff \nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPDISCOVER(eth0) 4e:70:ba:1e:73:ff \nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPOFFER(eth0) 10.0.61.210 4e:70:ba:1e:73:ff \nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPREQUEST(eth0) 10.0.61.210 4e:70:ba:1e:73:ff \n# DHCPACK for test-b: IP assigned is 10.0.61.210\nJan 16 22:57:48 vmbr1-dnsmasq daemon.info dnsmasq-dhcp[741]: DHCPACK(eth0) 10.0.61.210 4e:70:ba:1e:73:ff test-b\n\nNow we should be able to ping to each other either by their IP or by their hostname/FQDN:\n\n\ntest-a --> test-b checks:\n\n# test-a pings test-b using IP\ntest-a:~# ping -c1 10.0.61.210\nPING 10.0.61.210 (10.0.61.210): 56 data bytes\n64 bytes from 10.0.61.210: seq=0 ttl=64 time=0.072 ms\n\n--- 10.0.61.210 ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.072/0.072/0.072 ms\n\n# test-a pings test-b using hostname\ntest-a:~# ping -c1 test-b\nPING test-b (10.0.61.210): 56 data bytes\n64 bytes from 10.0.61.210: seq=0 ttl=64 time=0.063 ms\n\n--- test-b ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.063/0.063/0.063 ms\n\n# test-a pings test-b using FQDN\ntest-a:~# ping -c1 test-b.pve-internal.protossnet.local\nPING test-b.pve-internal.protossnet.local (10.0.61.210): 56 data bytes\n64 bytes from 10.0.61.210: seq=0 ttl=64 time=0.047 ms\n\n--- test-b.pve-internal.protossnet.local ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.047/0.047/0.047 ms\n\n\n\ntest-a <-- test-b checks:\n\n# test-a pings test-b using IP\ntest-b:~# ping -c1 10.0.4.102\nPING 10.0.4.102 (10.0.4.102): 56 data bytes\n64 bytes from 10.0.4.102: seq=0 ttl=64 time=0.074 ms\n\n--- 10.0.4.102 ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.074/0.074/0.074 ms\n\n# test-a pings test-b using hostname\nPING test-a (10.0.4.102): 56 data bytes\n64 bytes from 10.0.4.102: seq=0 ttl=64 time=0.047 ms\n\n--- test-a ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.047/0.047/0.047 ms\n\n# test-a pings test-b using FQDN\ntest-b:~# ping -c1 test-a.pve-internal.protossnet.local\nPING test-a.pve-internal.protossnet.local (10.0.4.102): 56 data bytes\n64 bytes from 10.0.4.102: seq=0 ttl=64 time=0.031 ms\n\n--- test-a.pve-internal.protossnet.local ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.031/0.031/0.031 ms\n\n\n\n\n\n\n\nBonus check: ping outside devices\n\n\n\n\n\nThe vmbr1 interface is NATed, so any device within the original range of the Proxmox server IP should be reachable:\n\n\nExternal servers check:\n\n# Ping to Proxmox server through its external FQDN\ntest-b:~# ping -c1 pve.protossnet.local\nPING pve.protossnet.local (192.168.1.5): 56 data bytes\n64 bytes from 192.168.1.5: seq=0 ttl=64 time=0.041 ms\n\n--- pve.protossnet.local ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.041/0.041/0.041 ms\n\n# Ping to PiHole through its given FQDN\ntest-b:~# ping -c1 pi.hole\nPING pi.hole (192.168.1.6): 56 data bytes\n64 bytes from 192.168.1.6: seq=0 ttl=63 time=0.176 ms\n\n--- pi.hole ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.176/0.176/0.176 ms\n\n# Ping to PiHole through its external FQDN\ntest-b:~# ping -c1 pi-hole.protossnet.local\nPING pi-hole.protossnet.local (192.168.1.6): 56 data bytes\n64 bytes from 192.168.1.6: seq=0 ttl=63 time=0.141 ms\n\n--- pi-hole.protossnet.local ping statistics ---\n1 packets transmitted, 1 packets received, 0% packet loss\nround-trip min/avg/max = 0.141/0.141/0.141 ms"
  },
  {
    "objectID": "homelab-project/virtualization-server/04-proxy-http-https-into-internal-network.html",
    "href": "homelab-project/virtualization-server/04-proxy-http-https-into-internal-network.html",
    "title": "Part 4 - Proxy HTTP(S) into the internal network",
    "section": "",
    "text": "We want to use Nginx as reverse proxy to make HTTP(S) requests to internal machines without noticing that they are actually on a private network.\n\n\n\nSomeone requests test-a.pve-internal.protossnet.local\n\nWe need to make sure the domain resolves to our Proxmox server (HOW???)\n\nIf HTTPS is being used, Nginx provides a valid TLS certificate\n\nWe need a wildcard certificate for *.pve-internal.protoss.local (HOW???)\n\nNginx proxies the request to the internal machine\n\nIt uses the same protocol that is being requested"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "DevOps Projects"
  }
]